# Face-generation-based-on-description-
Face generation based on description 


This project tackles the fascinating challenge of creating human-like face images from written descriptions. It is using an advanced method with StyleGAN architecture, which connects text to image creation. This allows to turn descriptions into face pictures. It was trained using a set of text and face pairs. Additionally, was explored image changes using GAN techniques, allowing to modify faces based on text cues.

Data Collection:

Data was gathered from two main sources:

The CelebA-Dialog repository (https://github.com/ziqihuangg/CelebA-Dialog) has a bunch of 30,000 high-quality face images. Each image is big, 1024 x 1024 pixels. This also comes with labels for 40 facial features from CelebAMask-HQ.

The MM-CelebA-HQ-Dataset repository (https://github.com/IIGROUP/MM-CelebA-HQ-Dataset) provides text descriptions linked to CelebAMask-HQ images. These descriptions are from earlier work and play a key role in our project.
